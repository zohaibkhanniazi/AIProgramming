# -*- coding: utf-8 -*-
"""Assignment2 programming

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a5d9Jjce0O2UKNjH6whXHoCao6xXdQ46
"""

#API Key= jina_393e73b38303480eb316b23036e665e41LDXYB_ZwNh-DkKhuqczT23z3u2S
from PIL import Image, ImageTk
from transformers import AutoModel
from tkinter import *
from tkinter import filedialog
import tkinter as tk
import fpdf
import cv2
import numpy as np
import pytesseract
from PIL import Image
import subprocess
from spellchecker import SpellChecker

# Initialize Tkinter window
window = Tk()
window.title('AAD App for Anomalies Detection')
langg = 'eng'
window.geometry("800x650")
window.config(background="white")

# Information Label
reg_info = Label(window, text="App for Anomalies Detection", width='80', height='2', font=("ariel", 12, "bold"), fg="green", bg='lightgreen')
reg_info.place(x=370, y=18, anchor='center')

# Start for Error check
label = Label(window)
label.place(x=100, y=100)  # You can adjust the position (x, y) as needed
label_file_explorer = Label(window, text="", font=("ariel", 10, "bold"), width=40, height=30, fg="blue")
label_file_explorer.place(x=10, y=65)
def change_button_text():
    button_explore.config(text="File Selected")

def SpellChk():
    global MasterPaper, TestPaper
    spell = SpellChecker()
    text = TestPaper
    misspelled = spell.unknown(text.split())
    num_errors = len(misspelled)
    for word in misspelled:
        corrected = spell.correction(word)
        text = text.replace(word, corrected)
    TestPaper = text
    
    # Clear window and update UI with results
    for widget in window.winfo_children():
        widget.destroy()
    window.geometry("800x650")
    reg_info = Label(window, text="Anomalies Detection", width=80, height=2, font=("ariel", 12, "bold"), fg="black", bg='lightgrey')
    reg_info.place(x=370, y=18, anchor='center')

    OutPut = f"Misspelled words: {', '.join(misspelled)} | Total errors: {num_errors}"
    label_file_explorer = Label(window, text=OutPut, font=("ariel", 10, "bold"), width=40, height=30, fg="blue")
    label_file_explorer.place(x=10, y=65)

def OpenTestFile():
    subprocess.Popen(['python', 'ForAnotherFileOpening.py'])
    subprocess.call(['python', 'ForAnotherFileOpening.py'])

def exit_application():
    window.destroy()

def browseFiles():
    global myimg
    global langg, MasterPaper, TestPaper
    py = r"*.png *.jpg *jpeg"
    filename = filedialog.askopenfilename(initialdir="/", title="Select a File", filetypes=(("images", py), ("all files", "*.*")))

    if filename == "":
        return
    if filename:
        image = Image.open(filename)
        photo = ImageTk.PhotoImage(image)
        label.config(image=photo)
        label.image = photo

    img = cv2.imread(filename)
    myimg = img
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    kernel = np.ones((1, 1), np.uint8)
    img = cv2.dilate(img, kernel, iterations=1)
    img = cv2.erode(img, kernel, iterations=1)
    cv2.imwrite("removed_noise.png", img)
    cv2.imwrite(filename, img)
    
    result = pytesseract.image_to_string(Image.open(filename), lang=langg)
    label_file_explorer.configure(text=result)
    image2 = myimg

    if button_explore.cget("text") == "Scan Master Copy":
        MasterPaper = result
    else:
        TestPaper = result
    
    change_button_text()

def on_radio_button_selected():
    global langg
    langg = language_var.get()
    print(langg)

button_explore = Button(window, text="Select DataSet", fg="white", bg="black", font=("ariel", 10, "bold"), width=20, command=browseFiles)
button_explore.place(x=280, y=600)

exit_button = Button(window, text="EXIT", fg="white", bg="black", font=("ariel", 10, "bold"), width=20, command=exit_application)
exit_button.place(x=100, y=600)

Redraw_button = Button(window, text="Find_Anomalies", fg="white", bg="black", font=("ariel", 10, "bold"), width=20, command=SpellChk)
Redraw_button.place(x=110, y=550)

window.mainloop()

import pandas as pd
import numpy as np
import nltk
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.cross_validation import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import re
import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import google.generativeai as genai
import google.ai.generativelanguage as glm
from google.colab import userdata
from sklearn.datasets import fetch_20newsgroups
from sklearn.datasets import fetch_rcv1
from sklearn.manifold import TSNE

df = pd.read_csv('spam.csv', encoding='latin-1')
df = df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)
df = df.replace(['ham','spam'],[0, 1])
df['Count']=0
for i in np.arange(0,len(df.v2)):
    df.loc[i,'Count'] = len(df.loc[i,'v2'])
cv = CountVectorizer()
x = cv.fit_transform(corpus).toarray()
le = LabelEncoder()
y = le.fit_transform(y)
y = df['v1']
xtrain, xtest, ytrain, ytest = train_test_split(x, y,test_size= 0.20, random_state = 0)
A_KEY=userdata.get('jina_393e73b38303480eb316b23036e665e41LDXYB_ZwNh-DkKhuqczT23z3u2S')
genai.configure(api_key=A_KEY)
NG_train = fetch_20newsgroups(subset='train')
NG_train.target_names
#PreProcessing
idx = NG_train.data[0].index('Lines')
print(NG_train.data[0][idx:])
NG_train.data = [re.sub(r'[\w\.-]+@[\w\.-]+', '', d) for d in NG_train.data]
NG_train.data = [re.sub(r"\([^()]*\)", "", d) for d in NG_train.data]
NG_train.data = [d.replace("From: ", "") for d in NG_train.data]
NG_train.data = [d.replace("\nSubject: ", "") for d in NG_train.data]
NG_train.data = [d[0:5000] if len(d) > 5000 else d for d in NG_train.data]
df_train = pd.DataFrame(NG_train.data, columns=['Text'])
df_train['Label'] = NG_train.target
df_train['Class Name'] = df_train['Label'].map(NG_train.target_names.__getitem__)

SAMPLE_SIZE = 110
df_train = (df_train.groupby('Label', as_index = False)
                    .apply(lambda x: x.sample(SAMPLE_SIZE))
                    .reset_index(drop=True))

# Select the science data
df_train = df_train[df_train['Class Name'].str.contains('sci')]
df_train = df_train.reset_index()
df_train['Text']
print(df_train)
text_series=df_train['Text']
txt= text_series.tolist()
print(txt)
from tqdm.auto import tqdm
tqdm.pandas()
import torch
from transformers import AutoTokenizer, AutoModel
from sentence_transformers import SentenceTransformer, util
model_name = 'models/paraphrase-MiniLM-L6-v2'
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

from google.api_core import retry

def make_embed_text_fn(model):

  @retry.Retry(timeout=300.0)
  def embed_fn(text: str) -> list[float]:
    # for CLUSTERING.
    embedding = genai.embed_content(model='models/embedding-001',
                                    content=text,
                                    task_type="clustering")['embedding']
    return np.array(embedding)

  return embed_fn


def create_embeddings(df):
  model='paraphrase-MiniLM-L6-v2'
  df['Embeddings'] = df['Text'].progress_apply(make_embed_text_fn(model))
  return df

df_train = create_embeddings(df_train)
df_train.drop('index', axis=1, inplace=True)
X = np.array(df_train['Embeddings'].to_list(), dtype=np.float32)
print(X.shape)
tsne = TSNE(random_state=0, n_iter=1000)
tsne_results = tsne.fit_transform(X)
df_tsne = pd.DataFrame(tsne_results, columns=['TSNE1', 'TSNE2'])
df_tsne['Class Name'] = df_train['Class Name']
df_tsne
fig, ax = plt.subplots(figsize=(8,6))
sns.set_style('darkgrid', {"grid.color": ".6", "grid.linestyle": ":"})
sns.scatterplot(data=df_tsne, x='TSNE1', y='TSNE2', hue='Class Name', palette='Set2')
sns.move_legend(ax, "upper left", bbox_to_anchor=(1, 1))
plt.title('Scatter plot for data using t-SNE')
plt.xlabel('TSNE_1')
plt.ylabel('TSNE_2')

#for getting centroid of the clusters
def get_centroids(df_tsne):
  centroids = df_tsne.groupby('Class Name').mean()
  return centroids
centroids = get_centroids(df_tsne)
print(centroids)
def get_embedding_centroids(df):
  emb_centroids = dict()
  grouped = df.groupby('Class Name')
  for c in grouped.groups:
    sub_df = grouped.get_group(c)
    emb_centroids[c] = np.mean(sub_df['Embeddings'], axis=0)
  return emb_centroids
# To show centroids and cluster
fig, ax = plt.subplots(figsize=(4,2))
sns.set_style('darkgrid', {"grid.color": ".6", "grid.linestyle": ":"})
sns.scatterplot(data=df_tsne, x='TSNE1', y='TSNE2', hue='Class Name', palette='Set2');
sns.scatterplot(data=centroids, x='TSNE1', y='TSNE2', color="black", marker='X', s=100, label='Centroids')
sns.move_legend(ax, "upper left", bbox_to_anchor=(1, 1))
plt.title('Scatter plot with t-SNE and centroids')
plt.xlabel('TSNE1')
plt.ylabel('TSNE2');

def calculate_euclidean_distance(p1, p2):
  return np.sqrt(np.sum(np.square(p1 - p2)))
def detect_outlier(df, emb_centroids, radius):
  for idx, row in df.iterrows():
    class_name = row['Class Name']
    dist = calculate_euclidean_distance(row['Embeddings'],
                                        emb_centroids[class_name])
    df.at[idx, 'Outlier'] = dist > radius

  return len(df[df['Outlier'] == True])
range_ = np.arange(0.4, 0.6, 0.02).round(decimals=2).tolist()
num_outliers = []
for i in range_:
  num_outliers.append(detect_outlier(df_train, emb_c, i))
fig = plt.figure(figsize = (3, 2))
plt.rcParams.update({'font.size': 7})
plt.bar(list(map(str, range_)), num_outliers)
plt.title("Number of outliers vs. distance of points from centroid")
plt.xlabel("Distance from centroid")
plt.ylabel("Number of outliers")
for i in range(len(range_)):
  plt.text(i, num_outliers[i], num_outliers[i], ha = 'center')
plt.show()

NearOutlier = 0.5
RealOutlier = 0.8
detect_outlier(df_train, emb_c, NearOutlier)
detect_outlier(df_train, emb_c, RealOutlier)
df_Nearoutlier = df_train[df_train['Outlier'] == True]
#show Near outliers
print(df_Nearoutlier.head())
df_Realoutlier = df_train[df_train['Outlier'] == True]
#show Real Outliers
print(df_Realoutlier.head())
N_Outlier_proj = df_tsne.loc[df_Nearoutlier['Outlier'].index]
R_Outlier_proj = df_tsne.loc[df_Realoutlier['Outlier'].index]

fig, ax = plt.subplots(figsize=(4,2))
plt.rcParams.update({'font.size': 10})
sns.set_style('darkgrid', {"grid.color": ".6", "grid.linestyle": ":"})
sns.scatterplot(data=df_tsne, x='TSNE1', y='TSNE2', hue='Class Name', palette='Set2');
sns.scatterplot(data=centroids, x='TSNE1', y='TSNE2', color="black", marker='X', s=100, label='Centroids')
# Draw a red circle around the outliers
sns.scatterplot(data=Routlier_proj, x='TSNE1', y='TSNE2', color='green', marker='o', alpha=0.5, s=90, label='Real Outliers')
sns.move_legend(ax, "upper left", bbox_to_anchor=(1, 1))
plt.title('Scatter plot for Real outliers')
plt.xlabel('TSNE1')
plt.ylabel('TSNE2')

sns.scatterplot(data=Noutlier_proj, x='TSNE1', y='TSNE2', color='green', marker='o', alpha=0.5, s=90, label='Near Outliers')
sns.move_legend(ax, "upper left", bbox_to_anchor=(1, 1))
plt.title('Scatter plot for Near projected outliers')
plt.xlabel('TSNE1')
plt.ylabel('TSNE2')

#for printing outlier in textual form
sci_crypt_outliers = df_Nearoutlier[df_outliers['Class Name'] == 'sci.crypt']
print(sci_crypt_outliers['Text'].iloc[0])

sci_elec_outliers = df_Rearoutlier[df_outliers['Class Name'] == 'sci.electronics']
print(sci_elec_outliers['Text'].iloc[0])

sci_med_outliers = df_Nearoutlier[df_outliers['Class Name'] == 'sci.med']
print(sci_med_outliers['Text'].iloc[0])
